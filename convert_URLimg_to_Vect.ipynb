{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbP5vZRYeHmlqWGR8FUMzZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1337Rinz/img_retrieval_vectorDB/blob/main/convert_URLimg_to_Vect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y grpcio pymilvus  # Uninstall existing versions, if any\n",
        "!pip install grpcio==1.63.0 pymilvus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_laDkNEE3aFB",
        "outputId": "2d36d099-ea3e-47c8-d818-95892f689665"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: grpcio 1.64.1\n",
            "Uninstalling grpcio-1.64.1:\n",
            "  Successfully uninstalled grpcio-1.64.1\n",
            "\u001b[33mWARNING: Skipping pymilvus as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting grpcio==1.63.0\n",
            "  Downloading grpcio-1.63.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pymilvus\n",
            "  Downloading pymilvus-2.4.4-py3-none-any.whl (196 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=67 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (67.7.2)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (3.20.3)\n",
            "Collecting environs<=9.5.0 (from pymilvus)\n",
            "  Downloading environs-9.5.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting ujson>=2.0.0 (from pymilvus)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (2.0.3)\n",
            "Collecting milvus-lite<2.5.0,>=2.4.0 (from pymilvus)\n",
            "  Downloading milvus_lite-2.4.8-py3-none-manylinux2014_x86_64.whl (49.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow>=3.0.0 (from environs<=9.5.0->pymilvus)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv (from environs<=9.5.0->pymilvus)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from milvus-lite<2.5.0,>=2.4.0->pymilvus) (4.66.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus) (1.25.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow>=3.0.0->environs<=9.5.0->pymilvus) (24.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus) (1.16.0)\n",
            "Installing collected packages: ujson, python-dotenv, milvus-lite, marshmallow, grpcio, environs, pymilvus\n",
            "Successfully installed environs-9.5.0 grpcio-1.63.0 marshmallow-3.21.3 milvus-lite-2.4.8 pymilvus-2.4.4 python-dotenv-1.0.1 ujson-5.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)  # This will restart the kernel"
      ],
      "metadata": {
        "id": "B41xzk1i4u8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show grpcio pymilvus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFlV1Bwn5MhM",
        "outputId": "3e096802-bfcf-4021-a1f3-e3aed5a9654a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: grpcio\n",
            "Version: 1.63.0\n",
            "Summary: HTTP/2-based RPC framework\n",
            "Home-page: https://grpc.io\n",
            "Author: The gRPC Authors\n",
            "Author-email: grpc-io@googlegroups.com\n",
            "License: Apache License 2.0\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: \n",
            "Required-by: google-cloud-pubsub, grpc-google-iam-v1, grpcio-status, pymilvus, tensorboard, tensorflow\n",
            "---\n",
            "Name: pymilvus\n",
            "Version: 2.4.4\n",
            "Summary: Python Sdk for Milvus\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: Milvus Team <milvus-team@zilliz.com>\n",
            "License: \n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: environs, grpcio, milvus-lite, pandas, protobuf, setuptools, ujson\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import requests\n",
        "from pymilvus import MilvusClient\n",
        "import json"
      ],
      "metadata": {
        "id": "79oYJM3o3TKL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_array(url: str) -> np.ndarray:\n",
        "    '''\n",
        "    No preprocess, reshape, resize,...\n",
        "    '''\n",
        "    response = requests.get(url)\n",
        "    image_array = np.asarray(bytearray(response.content), dtype=\"uint8\")\n",
        "    # Đọc ảnh bằng OpenCV\n",
        "    img = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
        "    return img\n",
        "\n",
        "\n",
        "def connect_vector_db(key_dir):\n",
        "    # Đọc tệp JSON\n",
        "    with open(key_dir, 'r') as file:\n",
        "        config = json.load(file)\n",
        "\n",
        "    cluster_endpoint = config['CLUSTER_ENDPOINT']\n",
        "    token = config['TOKEN']\n",
        "    client = MilvusClient(uri=cluster_endpoint, token=token)\n",
        "    return client\n",
        "\n",
        "\n",
        "def get_describe_db(client, collections):\n",
        "    return client.describe_collection(collections)\n",
        "\n",
        "\n",
        "def insert_vector_db(client, collection, data):\n",
        "    return client.insert(collection, data=data)\n",
        "\n",
        "\n",
        "def delete_all_db(client, collection):\n",
        "    return client.delete(collection_name=collection, filter='Auto_id >= 0')"
      ],
      "metadata": {
        "id": "C0BUp4Qx3cII"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFViTModel, AutoImageProcessor\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "HlDxrU7Q3C3J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_processor = AutoImageProcessor.from_pretrained(\n",
        "    \"google/vit-base-patch16-224-in21k\")\n",
        "vit_model = TFViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjKTO-EZ6nJZ",
        "outputId": "498b885c-db7b-421c-a4fe-a92f39353068"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "All PyTorch model weights were used when initializing TFViTModel.\n",
            "\n",
            "All the weights of TFViTModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFViTModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"/content/dta.xlsx\""
      ],
      "metadata": {
        "id": "e0tJplRX53K0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XGKiFVrT2uQR"
      },
      "outputs": [],
      "source": [
        "# -----------ĐỌC FILE EXCEL-------------\n",
        "df = pd.read_excel(filepath)\n",
        "url_list = df['URL'].to_list()\n",
        "describe_list = df['Describe'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm  # Import tqdm for progress bar\n",
        "import cv2\n",
        "import requests\n",
        "\n",
        "# -----------LẤY ẢNH TỪ URL v1.2--------------\n",
        "tensor = []\n",
        "for url in tqdm(url_list, desc=\"Processing Images\"):\n",
        "    # Fetch image from URL using custom function\n",
        "    img = get_array(url)\n",
        "    process = image_processor(img, return_tensors=\"np\")['pixel_values']\n",
        "    tensor.append(process[0])\n",
        "\n",
        "\n",
        "tensor = np.array(tensor)\n",
        "print(tensor.shape)\n",
        "print('Get image: DONE')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaxkNaJq67XE",
        "outputId": "c1295806-ba0a-498d-d11f-25839d62c93d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Images: 100%|██████████| 6/6 [00:02<00:00,  2.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6, 3, 224, 224)\n",
            "Get image: DONE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------CALCULATE VECTOR------------\n",
        "n_samples = tensor.shape[0]\n",
        "predictions = []\n",
        "batch_size = 32\n",
        "\n",
        "for start in tqdm(range(0, n_samples, batch_size), desc=\"Calculating Vectors\"):\n",
        "    end = min(start + batch_size, n_samples)\n",
        "    batch_predictions = vit_model(tensor[start:end])['pooler_output'].numpy()\n",
        "    predictions.append(batch_predictions)\n",
        "\n",
        "# Stack predictions into a single numpy array\n",
        "predictions = np.vstack(predictions)\n",
        "# (n, 768)\n",
        "print(\"VECTOR CALCULATED\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKeXG7dH_zls",
        "outputId": "736ec584-870e-4540-f127-aabac30a83ef"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating Vectors: 100%|██████████| 1/1 [00:05<00:00,  5.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VECTOR CALCULATED\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------INSERT TO DB-----------------\n",
        "insert_data = []\n",
        "for vector, url, describe in zip(predictions, url_list, describe_list):\n",
        "    insert_data.append({\n",
        "        'vector': vector.tolist(),\n",
        "        'url': url,\n",
        "        'describe': describe\n",
        "    })\n",
        "\n",
        "client = connect_vector_db('secret_key.json')\n",
        "result = insert_vector_db(client, 'ViT', insert_data)\n",
        "client.close()\n",
        "print(\"INSERTED TO DB\")"
      ],
      "metadata": {
        "id": "KogBy7PANymu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}